{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "188MxOVzzM0s"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hashU43LAyV6"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQzJw1YIlsh_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.metrics import TruePositives, TrueNegatives, FalsePositives, FalseNegatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyoIDh2-3bYe"
      },
      "outputs": [],
      "source": [
        "path_API_autentification_token= '/content/drive/MyDrive/BigData Pneumonia Project'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncE1TajKl516"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = path_API_autentification_token\n",
        "\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "\n",
        "zip_ref = zipfile.ZipFile('chest-xray-pneumonia.zip', 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUWVqEMk2_sZ"
      },
      "outputs": [],
      "source": [
        "train_dir = '/tmp/chest_xray/train'\n",
        "val_dir = '/tmp/chest_xray/val'\n",
        "test_dir = '/tmp/chest_xray/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wew_8n4d3WdC"
      },
      "outputs": [],
      "source": [
        "img_height = 128\n",
        "img_width = 128\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ7ZB7VF3eCQ"
      },
      "outputs": [],
      "source": [
        "train_df = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    color_mode = 'grayscale',\n",
        "    image_size = (img_height,img_width),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_df = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    color_mode = 'grayscale',\n",
        "    image_size = (img_height,img_width),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_df = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    color_mode = 'grayscale',\n",
        "    image_size = (img_height,img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZ0GP_TC9MMP"
      },
      "outputs": [],
      "source": [
        "train_labels = []\n",
        "test_labels = []\n",
        "val_labels = []\n",
        "\n",
        "for images, labels in train_df.unbatch():\n",
        "  train_labels.append(labels.numpy())\n",
        "\n",
        "for images, labels in test_df.unbatch():\n",
        "  test_labels.append(labels.numpy())\n",
        "\n",
        "for images, labels in val_df.unbatch():\n",
        "  val_labels.append(labels.numpy())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Count values of instances per label in train dataset\\n\")\n",
        "print(pd.DataFrame(np.unique(train_labels, return_counts = True), index=['Label', 'count'], columns=['Normal','Pneumonia']))\n",
        "print(\"\\n\\nCount values of instances per label in test dataset\\n\")\n",
        "print(pd.DataFrame(np.unique(test_labels, return_counts = True), index=['Label', 'count'], columns=['Normal','Pneumonia']))\n",
        "print(\"\\n\\nCount values of instances per label in validation dataset\\n\")\n",
        "print(pd.DataFrame(np.unique(val_labels, return_counts = True), index=['Label', 'count'], columns=['Normal','Pneumonia']))"
      ],
      "metadata": {
        "id": "YZg8ROXXOQGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egzl5NOV4h5D"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_df.take(1):\n",
        "    for i in range(9):\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(np.squeeze(images[i].numpy().astype(\"uint8\")))\n",
        "        plt.title(train_df.class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w_wa9fi5PIF"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_df = train_df.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_df = val_df.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_df = test_df.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NK26x-NoOUWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2JNHBXHu2B_"
      },
      "outputs": [],
      "source": [
        "appname = \"Predicting pneumonia\"\n",
        "\n",
        "spark_mirror = \"https://archive.apache.org/dist/spark\"\n",
        "spark_version = \"3.3.1\"\n",
        "hadoop_version = \"3\"\n",
        "\n",
        "! apt-get update\n",
        "! apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "! rm -rf spark-{spark_version}-bin-hadoop{hadoop_version}.tgz spark-{spark_version}-bin-hadoop{hadoop_version}\n",
        "! wget -q {spark_mirror}/spark-{spark_version}/spark-{spark_version}-bin-hadoop{hadoop_version}.tgz\n",
        "! tar xzf spark-{spark_version}-bin-hadoop{hadoop_version}.tgz\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/spark-{spark_version}-bin-hadoop{hadoop_version}\"\n",
        "\n",
        "! pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(appname).master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_aYa5jSvf0E"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import lit\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.mllib.linalg import Vectors, VectorUDT\n",
        "from pyspark.ml.image import ImageSchema\n",
        "from pyspark.sql.types import ArrayType, IntegerType, StringType\n",
        "from pyspark.sql.functions import rand # shuffling\n",
        "import cv2 # image preprocessing\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ha-2d53xvNEp"
      },
      "outputs": [],
      "source": [
        "import glob2\n",
        "\n",
        "train_normal_cases = glob2.glob(train_dir + '/NORMAL/' + '*jpeg')\n",
        "train_pneumonia_cases = glob2.glob(train_dir + '/PNEUMONIA/' + '*jpeg')\n",
        "\n",
        "test_normal_cases = glob2.glob(test_dir + '/NORMAL/' + '*jpeg')\n",
        "test_pneumonia_cases = glob2.glob(test_dir + '/PNEUMONIA/'+ '*jpeg')\n",
        "\n",
        "val_normal_cases = glob2.glob(val_dir + '/NORMAL/' + '*jpeg')\n",
        "val_pneumonia_cases = glob2.glob(val_dir + '/PNEUMONIA/' + '*jpeg')\n",
        "\n",
        "columns = [\"path\", \"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ2hZwRxvOMr"
      },
      "outputs": [],
      "source": [
        "data_tr_normal = [[path_train_normal, 0.0] for path_train_normal in train_normal_cases]\n",
        "data_tr_pneumonia = [[path_train_pneumonia, 1.0] for path_train_pneumonia in train_pneumonia_cases]\n",
        "\n",
        "train_normal_df = spark.createDataFrame(data_tr_normal, columns)\n",
        "train_pneumonia_df = spark.createDataFrame(data_tr_pneumonia, columns)\n",
        "\n",
        "train_df = train_normal_df.unionAll(train_pneumonia_df)\n",
        "\n",
        "train_df = train_df.repartition(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtAUcMVuv90z"
      },
      "outputs": [],
      "source": [
        "data_te_normal = [[path_test_normal, 0.0] for path_test_normal in test_normal_cases]\n",
        "data_te_pneumonia = [[path_test_pneumonia, 1.0] for path_test_pneumonia in test_pneumonia_cases]\n",
        "\n",
        "test_normal_df = spark.createDataFrame(data_te_normal, columns)\n",
        "test_pneumonia_df = spark.createDataFrame(data_te_pneumonia, columns)\n",
        "\n",
        "test_df = test_normal_df.unionAll(test_pneumonia_df)\n",
        "\n",
        "test_df = test_df.repartition(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIu4rzFAwEsT"
      },
      "outputs": [],
      "source": [
        "data_v_normal = [[path_val_normal, 0.0] for path_val_normal in val_normal_cases]\n",
        "data_v_pneumonia = [[path_val_pneumonia, 1.0] for path_val_pneumonia in val_pneumonia_cases]\n",
        "\n",
        "val_normal_df = spark.createDataFrame(data_v_normal, columns)\n",
        "val_pneumonia_df = spark.createDataFrame(data_v_pneumonia, columns)\n",
        "\n",
        "val_df = val_normal_df.unionAll(val_pneumonia_df)\n",
        "\n",
        "val_df = val_df.repartition(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTE8dr-BwUU_"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.orderBy(rand())\n",
        "test_df = test_df.orderBy(rand())\n",
        "val_df = val_df.orderBy(rand())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YACC36hoFTPj"
      },
      "outputs": [],
      "source": [
        "val_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVX5PTHnFoJw"
      },
      "outputs": [],
      "source": [
        "val_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiQTPcpPFyNG"
      },
      "outputs": [],
      "source": [
        "train_df.groupBy('label').count().show()\n",
        "test_df.groupBy('label').count().show()\n",
        "val_df.groupBy('label').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEipftinD221"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "@F.udf(VectorUDT())\n",
        "def image_to_vector_udf(imagepath: StringType):\n",
        "  img = cv2.imread(imagepath) #read the image\n",
        "  img = cv2.resize(img, (32, 32)) #resize\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #change color scale to gray\n",
        "  img = img/255.0\n",
        "  img = np.reshape(img, (32,32,1)).flatten().tolist()\n",
        "  #flat_list = [item for sublist in img for item in sublist]\n",
        "  return Vectors.dense(img)\n",
        "\n",
        "\n",
        "train_df = train_df.withColumn(\"features\", image_to_vector_udf(train_df[\"path\"]))\n",
        "test_df = test_df.withColumn(\"features\", image_to_vector_udf(test_df[\"path\"]))\n",
        "val_df = val_df.withColumn(\"features\", image_to_vector_udf(val_df[\"path\"]))\n",
        "\n",
        "\n",
        "list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
        "\n",
        "train_df = train_df.select(\n",
        "    train_df[\"label\"],\n",
        "    list_to_vector_udf(train_df[\"features\"]).alias(\"features\")\n",
        ")\n",
        "\n",
        "test_df = test_df.select(\n",
        "    test_df[\"label\"],\n",
        "    list_to_vector_udf(test_df[\"features\"]).alias(\"features\")\n",
        ")\n",
        "\n",
        "val_df = val_df.select(\n",
        "    val_df[\"label\"],\n",
        "    list_to_vector_udf(val_df[\"features\"]).alias(\"features\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHxPsrzeGBra"
      },
      "outputs": [],
      "source": [
        "val_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvSEjh1KGJv0"
      },
      "outputs": [],
      "source": [
        "val_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zz7qOgY6Uek"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "estimator = RandomForestClassifier(labelCol='label')\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='label')\n",
        "\n",
        "rfc = estimator\n",
        "params = ParamGridBuilder() \\\n",
        "    .addGrid(rfc.numTrees, [ 20, 50, 100 ]) \\ #tạo một lưới để tìm kiếm numTrees tốt nhất trong số 20, 50 và 100\n",
        "    .addGrid(rfc.maxDepth, [ 3, 5, 7 ]) \\ #tìm kiếm maxDepth tốt nhất trong số 3, 5 và 7\n",
        "    .build()\n",
        "\n",
        "crossval = CrossValidator(estimator=estimator,\n",
        "                          estimatorParamMaps=params,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=4) #Tạo một phiên bản CrossValidator chỉ định công cụ ước tính, lưới tham số, bộ đánh giá và số lần gấp để xác thực chéo\n",
        "\n",
        "model_rf = crossval.fit(train_df) #Huấn luyện mô hình Rừng ngẫu nhiên bằng cách sử dụng xác thực chéo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ELvw5a0MqEw"
      },
      "outputs": [],
      "source": [
        "cvModel_rf = model_rf.bestModel #rích xuất mô hình tốt nhất từ CrossValidatorModel​​"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USrnQiGPMz7e"
      },
      "outputs": [],
      "source": [
        "print(\"Random Forest best model parameters: \\n----\")\n",
        "\n",
        "print('Best Param (numTrees): ', cvModel_rf._java_obj.getNumTrees())\n",
        "\n",
        "print('Best Param (maxDepth): ', cvModel_rf._java_obj.getMaxDepth())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBDnTV93NRBV"
      },
      "outputs": [],
      "source": [
        "print(\"\\nBest Model accuracy : \" , cvModel_rf.summary.accuracy) #Độ chính xác tổng thể của mô hình tốt nhất trên tập dữ liệu được đánh giá là khoảng 98%\n",
        "print(\"-------------\\nBest Model recall by label [0 - normal ,1 - pneumonia] \\n\\n \" , cvModel_rf.summary.recallByLabel) #tỉ lệ dương thực theo nhãn biểu thị việc thu hồi nhãn 0 ('bình thường') và nhãn 1 ('viêm phổi') tương ứng. Các giá trị này biểu thị tỷ lệ phần trăm các phiên bản được dự đoán chính xác của từng lớp\n",
        "print(\"-------------\\nBest Model precision by label [0 - normal ,1 - pneumonia] \\n\\n \" , cvModel_rf.summary.precisionByLabel) #số liệu đo lường độ chính xác của các dự đoán tích cực được đưa ra, tương ứng với độ chính xác tương ứng cho nhãn 0 (bình thường) và nhãn 1 (viêm phổi)\n",
        "print(\"-------------\\nBest Model False positive rate by label [0 - normal ,1 - pneumonia] \\n\\n \" , cvModel_rf.summary.falsePositiveRateByLabel) #biểu thị tỷ lệ dương tính giả tương ứng cho nhãn 0 (bình thường) và nhãn 1 (viêm phổi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrVSC7of68hf"
      },
      "outputs": [],
      "source": [
        "results_rf = model_rf.transform(test_df) #đánh giá mô hình Rừng ngẫu nhiên tốt nhất của mình trên tập dữ liệu thử nghiệm (test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4giU-rX7BiT"
      },
      "outputs": [],
      "source": [
        "Met_rf = evaluator.evaluate(results_rf)\n",
        "print(\"Test F1 score:\", Met_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNCY8pdFb-hM"
      },
      "outputs": [],
      "source": [
        "results_rf.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W0hIth-On6F"
      },
      "outputs": [],
      "source": [
        "from pyspark.mllib.evaluation import MulticlassMetrics #đánh giá thêm hiệu suất của mô hình trên dữ liệu thử nghiệm\n",
        "from pyspark import SparkContext\n",
        "sc=spark.sparkContext\n",
        "\n",
        "predictionAndLabels_rf = sc.parallelize(results_rf.select('label','prediction').toPandas().values.tolist()) #song hóa các nhãn dự đoán và nhãn thực tế từ dữ liệu thử nghiệm\n",
        "\n",
        "metrics_rf = MulticlassMetrics(predictionAndLabels_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn9jbRvjOqgQ"
      },
      "outputs": [],
      "source": [
        "# Tính toán độ chính xác, thu hồi và điểm F1 cho mỗi lớp (lớp 0,0 và lớp 1,0)\n",
        "labels = [0.0, 1.0]\n",
        "for label in sorted(labels):\n",
        "    print(\"Class %s precision = %s\" % (label, metrics_rf.precision(label))) #các trường hợp được dự đoán chính xác của loại 0/1 trong số tất cả các trường hợp của lớp 0/1 được dự đoán\n",
        "    print(\"Class %s recall = %s\" % (label, metrics_rf.recall(label))) #các trường hợp được dự đoán chính xác của lớp 0/1 trong số tất cả các trường hợp lớp 0/1 thực tế\n",
        "    print(\"Class %s F1 Measure = %s\" % (label, metrics_rf.fMeasure(label, beta=1.0))) #trung bình hài hòa của độ chính xác và độ thu hồi cho loại 0/1\n",
        "    print()\n",
        "print()\n",
        "\n",
        "# Các số liệu có trọng số được tính toán, có tính đến sự mất cân bằng của lớp. Độ chính xác có trọng số, mức thu hồi và điểm F1\n",
        "print(\"Weighted recall = %s\" % metrics_rf.weightedRecall)\n",
        "print(\"Weighted precision = %s\" % metrics_rf.weightedPrecision)\n",
        "print(\"Weighted F(1) Score = %s\" % metrics_rf.weightedFMeasure())\n",
        "print(\"Weighted F(0.5) Score = %s\" % metrics_rf.weightedFMeasure(beta=0.5))\n",
        "print(\"Weighted false positive rate = %s\" % metrics_rf.weightedFalsePositiveRate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_jWi4xSO6bf"
      },
      "outputs": [],
      "source": [
        "print(\"FP Metrics per label (normal, pneumonia): (\" , metrics_rf.falsePositiveRate(0.0), \",\",  metrics_rf.falsePositiveRate(1.0), \")\")\n",
        "#Tỷ lệ dương tính giả (FPR) cho mỗi nhãn lớp bằng cách sử dụng MulticlassMetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZi8_MG3PI7u"
      },
      "outputs": [],
      "source": [
        "conf_m_rf=metrics_rf.confusionMatrix().toArray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0mnkYuuPMj6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Plotting the confussion matrix as a heatmap\n",
        "plt.figure(figsize=(5,3))\n",
        "sns.set(font_scale=1.2)\n",
        "ax = sns.heatmap(conf_m_rf, annot=True,xticklabels=['H', 'P'], yticklabels=['H', 'P'], cbar=False, cmap='Blues',linewidths=1, linecolor='black', fmt='.0f')\n",
        "plt.yticks(rotation=0)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "ax.xaxis.set_ticks_position('top')\n",
        "plt.title('Confusion matrix - test data\\n(H - healthy/normal, P - pneumonia)')\n",
        "plt.show()\n",
        "# Ma trận nhầm lẫn cho thấy dự đoán của mô hình của bạn phù hợp như thế nào với các nhãn thực tế trên các lớp khác nhau."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA5z5lZN8FRs"
      },
      "outputs": [],
      "source": [
        "model.save('mlibmodel.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}